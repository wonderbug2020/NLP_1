{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries used for data importing and cleaning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "#Libraries used for TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Random forest library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#To score the results\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "tweet = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next I am going to concat the two datasets so that the data cleaning I do on them are equal\n",
    "df=pd.concat([tweet,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am going to drop the id, keyword, and location columns now\n",
    "df = df.drop(['id','keyword','location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of unique words in the text ##\n",
    "df_feature['num_words'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "## Number of characters in the text ##\n",
    "df_feature[\"num_unique_words\"] = df[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "## Number of stopwords in the text ##\n",
    "df_feature[\"num_chars\"] = df[\"text\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "## Number of title case words in the text ##\n",
    "df_feature[\"num_punctuations\"] =df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "## Number of title case words in the text ##\n",
    "df_feature[\"num_words_upper\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "## Average length of the words in the text ##\n",
    "df_feature[\"num_words_title\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "## Mean length of the words in the text ##\n",
    "df_feature[\"mean_word_len\"] = df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_words  num_unique_words  num_chars  num_punctuations  num_words_upper  \\\n",
       "0         13                13         69                 1                1   \n",
       "1          7                 7         38                 1                0   \n",
       "2         22                20        133                 3                0   \n",
       "3          8                 8         65                 2                0   \n",
       "4         16                15         88                 2                0   \n",
       "\n",
       "   num_words_title  mean_word_len  \n",
       "0                5       4.384615  \n",
       "1                5       4.571429  \n",
       "2                2       5.090909  \n",
       "3                1       7.125000  \n",
       "4                3       4.500000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 3 universal basic steps for data cleaning that apply to this data\n",
    "#Removing url's, html tags, and punctuation\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "#I am also going to add in the step of removing the emoji's and emoticons\n",
    "#They too few to be helpful but present enough to be annoying\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to execute the functions to cclean the data\n",
    "df['text']=df['text'].apply(lambda x : remove_URL(x))\n",
    "df['text']=df['text'].apply(lambda x : remove_html(x))\n",
    "df['text']=df['text'].apply(lambda x : remove_punct(x))\n",
    "df['text']=df['text'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to tokenize\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token = df.copy()\n",
    "df_token['text'] = df_token['text'].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  [our, deeds, are, the, reason, of, this, earth...     1.0\n",
       "1      [forest, fire, near, la, ronge, sask, canada]     1.0\n",
       "2  [all, residents, asked, to, shelter, in, place...     1.0\n",
       "3  [13000, people, receive, wildfires, evacuation...     1.0\n",
       "4  [just, got, sent, this, photo, from, ruby, ala...     1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next I am going to concat the two datasets so that the data cleaning I do on them are equal\n",
    "df_model=pd.concat([df_feature,df_token], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_words  num_unique_words  num_chars  num_punctuations  num_words_upper  \\\n",
       "0         13                13         69                 1                1   \n",
       "1          7                 7         38                 1                0   \n",
       "2         22                20        133                 3                0   \n",
       "3          8                 8         65                 2                0   \n",
       "4         16                15         88                 2                0   \n",
       "\n",
       "   num_words_title  mean_word_len  \\\n",
       "0                5       4.384615   \n",
       "1                5       4.571429   \n",
       "2                2       5.090909   \n",
       "3                1       7.125000   \n",
       "4                3       4.500000   \n",
       "\n",
       "                                                text  target  \n",
       "0  [our, deeds, are, the, reason, of, this, earth...     1.0  \n",
       "1      [forest, fire, near, la, ronge, sask, canada]     1.0  \n",
       "2  [all, residents, asked, to, shelter, in, place...     1.0  \n",
       "3  [13000, people, receive, wildfires, evacuation...     1.0  \n",
       "4  [just, got, sent, this, photo, from, ruby, ala...     1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df=df_model[df_model['target'].notnull()]\n",
    "test_df=df_model[df_model['target'].isnull()]\n",
    "X_train = training_df.drop('target', axis=1)\n",
    "y_train = training_df['target']\n",
    "X_test = test_df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>[just, happened, a, terrible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>[heard, about, earthquake, is, different, citi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.105263</td>\n",
       "      <td>[there, is, a, forest, fire, at, spot, pond, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfires]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>[typhoon, soudelor, kills, 28, in, china, and,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_words  num_unique_words  num_chars  num_punctuations  num_words_upper  \\\n",
       "0          6                 6         34                 0                0   \n",
       "1          9                 9         64                 3                0   \n",
       "2         19                19         96                 2                1   \n",
       "3          4                 4         40                 3                0   \n",
       "4          8                 8         45                 0                0   \n",
       "\n",
       "   num_words_title  mean_word_len  \\\n",
       "0                1       4.833333   \n",
       "1                1       6.222222   \n",
       "2                1       4.105263   \n",
       "3                2       9.250000   \n",
       "4                4       4.750000   \n",
       "\n",
       "                                                text  \n",
       "0          [just, happened, a, terrible, car, crash]  \n",
       "1  [heard, about, earthquake, is, different, citi...  \n",
       "2  [there, is, a, forest, fire, at, spot, pond, g...  \n",
       "3         [apocalypse, lighting, spokane, wildfires]  \n",
       "4  [typhoon, soudelor, kills, 28, in, china, and,...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to do some TF-IDF\n",
    "#I was getting an list has no attribute .lower error. I found this work around at \n",
    "#http://www.davidsbatista.net/blog/2018/02/28/TfidfVectorizer/\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word',\n",
    "                             tokenizer=dummy_fun,\n",
    "                             preprocessor=dummy_fun,\n",
    "                             token_pattern=None)\n",
    "tfidf_vect.fit(X_train['text'])\n",
    "X_train_vect = tfidf_vect.transform(X_train['text'])\n",
    "X_test_vect = tfidf_vect.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vect, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_selection.cross_val_score(rf, X_train_vect, y_train, cv=5, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
